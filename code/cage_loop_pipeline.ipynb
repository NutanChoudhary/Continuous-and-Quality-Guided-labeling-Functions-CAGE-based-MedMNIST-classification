{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.051524Z",
     "end_time": "2023-04-26T07:28:20.098432Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import enum\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from spear.labeling import PreLabels\n",
    "import numpy as np\n",
    "from spear.cage import Cage\n",
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# pip install decile-spear==1.0.6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.067175Z",
     "end_time": "2023-04-26T07:28:20.129684Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Declarning Class Labels\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "ABSTAIN = None\n",
    "\n",
    "class ClassLabels(enum.Enum):\n",
    "    CLASS1 = 0\n",
    "    CLASS2 = 1\n",
    "    CLASS3 = 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.082815Z",
     "end_time": "2023-04-26T07:28:20.129684Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LF class 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from spear.labeling import labeling_function, ABSTAIN, preprocessor, continuous_scorer\n",
    "import re\n",
    "path = \"D://project//data//models//\"\n",
    "\n",
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img\n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "    # print(confidence_scores)\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_0, label=ClassLabels.CLASS1)\n",
    "def LF_svm_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    svm = pickle.load(open(path+'0_svm.pkl','rb'))\n",
    "\n",
    "    if svm.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS1 # Return label only if confidence > 0.8\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=rf_0, label=ClassLabels.CLASS1)\n",
    "def LF_rf_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    rf = pickle.load(open(path+'0_rf.pkl','rb'))\n",
    "\n",
    "    if rf.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS1\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_0, label=ClassLabels.CLASS1)\n",
    "def LF_knn_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    knn = pickle.load(open(path+'0_knn.pkl','rb'))\n",
    "\n",
    "    if knn.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS1\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree\n",
    "@continuous_scorer()\n",
    "def dt_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=dt_0, label=ClassLabels.CLASS1)\n",
    "def LF_dt_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    dt = pickle.load(open(path+'0_dtc.pkl','rb'))\n",
    "\n",
    "    if dt.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS1\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_0(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=lr_0, label=ClassLabels.CLASS1)\n",
    "def LF_lr_0(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    lr = pickle.load(open(path+'0_lr.pkl','rb'))\n",
    "\n",
    "    if lr.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS1\n",
    "    else:\n",
    "        return ABSTAIN\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.098432Z",
     "end_time": "2023-04-26T07:28:20.129684Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LF class 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img\n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_1, label=ClassLabels.CLASS2)\n",
    "def LF_svm_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    svm = pickle.load(open(path+'1_svm.pkl','rb'))\n",
    "\n",
    "    if svm.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS2\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=rf_1, label=ClassLabels.CLASS2)\n",
    "def LF_rf_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    rf = pickle.load(open(path+'1_rf.pkl','rb'))\n",
    "\n",
    "    if rf.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS2\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_1, label=ClassLabels.CLASS2)\n",
    "def LF_knn_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    knn = pickle.load(open(path+'1_knn.pkl','rb'))\n",
    "\n",
    "    if knn.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS2\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree\n",
    "@continuous_scorer()\n",
    "def dt_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=dt_1, label=ClassLabels.CLASS2)\n",
    "def LF_dt_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    dt = pickle.load(open(path+'1_dtc.pkl','rb'))\n",
    "\n",
    "    if dt.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS2\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_1(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=lr_1, label=ClassLabels.CLASS2)\n",
    "def LF_lr_1(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    lr = pickle.load(open(path+'1_lr.pkl','rb'))\n",
    "\n",
    "    if lr.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS2\n",
    "    else:\n",
    "        return ABSTAIN\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.114057Z",
     "end_time": "2023-04-26T07:28:20.129684Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.129684Z",
     "end_time": "2023-04-26T07:28:20.145341Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LS class 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# SVM\n",
    "@continuous_scorer()\n",
    "def svm_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten() # x is 28x28x3 input img\n",
    "    svm = pickle.load(open(path+'2_svm.pkl','rb'))\n",
    "    confidence_scores = svm.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1]) #only called when model doesn't ABSTAIN, output confidence on class label\n",
    "\n",
    "@labeling_function(cont_scorer=svm_2, label=ClassLabels.CLASS3)\n",
    "def LF_svm_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    svm = pickle.load(open(path+'2_svm.pkl','rb'))\n",
    "\n",
    "    if svm.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS3\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Random Forest\n",
    "@continuous_scorer()\n",
    "def rf_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    rf = pickle.load(open(path+'2_rf.pkl','rb'))\n",
    "    confidence_scores = rf.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=rf_2, label=ClassLabels.CLASS3)\n",
    "def LF_rf_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    rf = pickle.load(open(path+'2_rf.pkl','rb'))\n",
    "\n",
    "    if rf.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS3\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# KNN\n",
    "@continuous_scorer()\n",
    "def knn_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    knn = pickle.load(open(path+'2_knn.pkl','rb'))\n",
    "    confidence_scores = knn.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "\n",
    "@labeling_function(cont_scorer=knn_2, label=ClassLabels.CLASS3)\n",
    "def LF_knn_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    knn = pickle.load(open(path+'2_knn.pkl','rb'))\n",
    "\n",
    "    if knn.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS3\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Decision Tree\n",
    "@continuous_scorer()\n",
    "def dt_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    dt = pickle.load(open(path+'2_dtc.pkl','rb'))\n",
    "    confidence_scores = dt.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=dt_2, label=ClassLabels.CLASS3)\n",
    "def LF_dt_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    dt = pickle.load(open(path+'2_dtc.pkl','rb'))\n",
    "\n",
    "    if dt.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS3\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "# Logistic Regression\n",
    "@continuous_scorer()\n",
    "def lr_2(x,**kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    lr = pickle.load(open(path+'2_lr.pkl','rb'))\n",
    "    confidence_scores = lr.predict_proba([x])\n",
    "\n",
    "    return float(confidence_scores[0][1])\n",
    "\n",
    "@labeling_function(cont_scorer=lr_2, label=ClassLabels.CLASS3)\n",
    "def LF_lr_2(x, **kwargs):\n",
    "    import pickle\n",
    "    import numpy as np\n",
    "\n",
    "    x = np.array(x).flatten()\n",
    "    lr = pickle.load(open(path+'2_lr.pkl','rb'))\n",
    "\n",
    "    if lr.predict_proba([x])[0][1]>0.8:\n",
    "        return ClassLabels.CLASS3\n",
    "    else:\n",
    "        return ABSTAIN\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.151851Z",
     "end_time": "2023-04-26T07:28:20.166805Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LFSET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from spear.labeling import LFSet\n",
    "\n",
    "LFS = [\n",
    "    LF_svm_0,\n",
    "    LF_rf_0,\n",
    "    LF_knn_0,\n",
    "    LF_dt_0,\n",
    "    LF_lr_0,\n",
    "    LF_svm_1,\n",
    "    LF_rf_1,\n",
    "    LF_knn_1,\n",
    "    LF_dt_1,\n",
    "    LF_lr_1,\n",
    "    LF_svm_2,\n",
    "    LF_rf_2,\n",
    "    LF_knn_2,\n",
    "    LF_dt_2,\n",
    "    LF_lr_2,\n",
    "]\n",
    "\n",
    "\n",
    "rules = LFSet(\"BM_LF\")\n",
    "rules.add_lf_list(LFS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.161356Z",
     "end_time": "2023-04-26T07:28:20.177317Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from utils import custom_dataset, train_all_LF\n",
    "from generate_LF import get_variables\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "dataset,x,y = custom_dataset(classes=classes,path=data_path ,fraction=label_frac)\n",
    "\n",
    "# 5% of Val Set to Test CNN after every iteration\n",
    "x_val, dummy1, y_val, dummy2 = train_test_split(dataset[\"val_images\"], dataset[\"val_labels\"], train_size=0.05)\n",
    "x_val = np.array(x_val).reshape(-1, 28, 28, 3)\n",
    "x_val = x_val.astype(\"float32\") / 255\n",
    "y_val = [int(i) for i in y_val]\n",
    "y_val = np_utils.to_categorical(y_val, num_classes=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.177317Z",
     "end_time": "2023-04-26T07:28:20.358211Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CAGE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def cage_loop(LFS, max_iters=10, threshold=10**-5, img_per_class = 100):\n",
    "    from cnn import create_cnn\n",
    "    from keras.utils import np_utils\n",
    "    # Paths\n",
    "    log_path_cage = './cage_loop/log.txt'\n",
    "    params_path = None\n",
    "    path_json = \"./cage_loop/labels.json\"\n",
    "    U_path_pkl = \"./cage_loop/unlabelled.pkl\"\n",
    "    L_path_pkl = \"./cage_loop/labelled.pkl\"\n",
    "\n",
    "    # Loading Data\n",
    "    classes,label_frac,data_path,save_path = get_variables()\n",
    "    print(\"Classes used in expt:\",classes)\n",
    "    dataset,x,y = custom_dataset(classes=classes, path=data_path, fraction=label_frac)\n",
    "    xu = np.array(dataset['rem_images'])\n",
    "    yu = np.array(dataset['rem_labels'])\n",
    "    print(np.shape(xu),np.shape(yu))\n",
    "    # Creating rules\n",
    "    n_lfs = len(LFS)\n",
    "    rules = LFSet(\"BM_LF\")\n",
    "    rules.add_lf_list(LFS)\n",
    "\n",
    "    confidence_list = []\n",
    "    val_scores = []\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        # Train Models in LFs\n",
    "        train_all_LF(x,y,len(classes),save_path,label_frac)\n",
    "\n",
    "        # Unlabelled\n",
    "        u_noisy_labels = PreLabels(name=\"bmnist_rem_ul\",\n",
    "                                    data=xu,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Lu,Su = u_noisy_labels.get_labels()\n",
    "        u_noisy_labels.generate_pickle(U_path_pkl)\n",
    "\n",
    "        # Labelled\n",
    "        l_noisy_labels = PreLabels(name=\"bmnist_l\",\n",
    "                                    data=x,\n",
    "                                    gold_labels=y,\n",
    "                                    rules=rules,\n",
    "                                    labels_enum=ClassLabels,\n",
    "                                    num_classes=len(classes))\n",
    "        # Ll,Sl = l_noisy_labels.get_labels()\n",
    "        l_noisy_labels.generate_pickle(L_path_pkl)\n",
    "        l_noisy_labels.generate_json(path_json)\n",
    "\n",
    "\n",
    "        # Cage\n",
    "        cage = Cage(path_json = path_json, n_lfs = n_lfs)\n",
    "        if params_path is not None:\n",
    "            cage.load_params(load_path = params_path)\n",
    "        else:\n",
    "            params_path = './cage_loop/params.pkl'\n",
    "\n",
    "        probs = cage.fit_and_predict_proba(path_pkl = U_path_pkl, path_test = L_path_pkl, path_log = log_path_cage, qt = 0.9, qc = 0.85, metric_avg = ['macro'], n_epochs = 100, lr = 0.01)\n",
    "        labels = np.argmax(probs, 1)\n",
    "\n",
    "        values, frequency = np.unique(yu, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Lake Class {values}: {frequency}\")\n",
    "\n",
    "        values, frequency = np.unique(y, return_counts=True)\n",
    "        for values, frequency in zip(values, frequency):\n",
    "            print(f\"Labels of Labelled Set {values}: {frequency}\")\n",
    "\n",
    "        print(\"=\"*45)\n",
    "        print(\"Iteration\",i)\n",
    "        print(\"Shape of Labeled Data:\",x.shape)\n",
    "        print(\"Shape of Unlabeled Data:\",xu.shape)\n",
    "        print(\"Accuracy on unlabelled images:\",accuracy_score(labels,yu)*100)\n",
    "        print(\"=\"*45)\n",
    "\n",
    "        cage.save_params(save_path = params_path)\n",
    "\n",
    "        confidence = np.array([np.max(i) for i in probs])\n",
    "        confidence_list.append(confidence)\n",
    "        print(i,probs.shape)\n",
    "\n",
    "        # Getting indices of probabilities in decreasing order\n",
    "        idx = np.argsort(confidence)\n",
    "        idx = idx[::-1]\n",
    "\n",
    "        # Number of images per class (5%)\n",
    "        # img_per_class = int(0.05*len(confidence)/len(classes))\n",
    "\n",
    "        # Number of images per class (50)\n",
    "\n",
    "\n",
    "        print(\"Num img per class =\",img_per_class)\n",
    "\n",
    "        pop_list = [] #list of indices of images to be added\n",
    "        label_count = []\n",
    "\n",
    "        for j in idx:\n",
    "            if confidence[j]>threshold and label_count.count(labels[j])<img_per_class:\n",
    "                pop_list.append(j)\n",
    "                label_count.append(labels[j])\n",
    "\n",
    "        print(\"Number of images getting transferred:\", len(pop_list))\n",
    "        print('Accuracy of Pseudo-labelled img added to dataset:', accuracy_score(labels[pop_list],yu[pop_list])*100)\n",
    "\n",
    "        x = np.append(x,xu[pop_list], axis=0)\n",
    "        y = np.append(y,labels[pop_list], axis=0)\n",
    "        xu = np.delete(xu,pop_list, axis=0)\n",
    "        yu = np.delete(yu,pop_list, axis=0)\n",
    "\n",
    "        if len(pop_list)<50:\n",
    "            break\n",
    "\n",
    "        # Deleting variables\n",
    "        del u_noisy_labels\n",
    "        del l_noisy_labels\n",
    "        del cage\n",
    "\n",
    "        classes,label_frac,data_path,save_path = get_variables()\n",
    "\n",
    "        x_train = x\n",
    "        x_train = np.array(x_train).reshape(-1, 28, 28, 3)\n",
    "        x_train = x_train.astype(\"float32\") / 255\n",
    "        y_train = [int(i) for i in y]\n",
    "        y_train = np_utils.to_categorical(y_train, len(classes))\n",
    "        batch_size = 128\n",
    "        epochs = 25\n",
    "        model = create_cnn(num_classes = 3)\n",
    "        model.summary()\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "        model.save(f'D://project//code//cnn//cage_trained_{i}.h5')\n",
    "        score = model.evaluate(x_val, y_val, verbose = 0)\n",
    "        val_scores.append(score[1]*100)\n",
    "        print(f\"CNN Test accuracy on Lake Set for iteration{i}: \", val_scores[i])\n",
    "        # if i>0 and val_scores[i]<val_scores[i-1]:\n",
    "        #     break\n",
    "\n",
    "\n",
    "    return x,y,xu,yu,confidence_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.358211Z",
     "end_time": "2023-04-26T07:28:20.373841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes used in expt: [2, 4, 5]\n",
      "(5806, 28, 28, 3) (5806,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MICCAI_Derma\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MICCAI_Derma\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\MICCAI_Derma\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained & Saved 6 models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5806/5806 [07:52<00:00, 12.28it/s]\n",
      "100%|██████████| 435/435 [00:31<00:00, 13.79it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_test_accuracy_score: 0.9977011494252873\n",
      "test_average_metric: macro\tfinal_test_f1_score: 0.997701122090235\n",
      "Labels of Lake Class 0: 624\n",
      "Labels of Lake Class 1: 634\n",
      "Labels of Lake Class 2: 4548\n",
      "Labels of Labelled Set 0: 145\n",
      "Labels of Labelled Set 1: 145\n",
      "Labels of Labelled Set 2: 145\n",
      "=============================================\n",
      "Iteration 0\n",
      "Shape of Labeled Data: (435, 28, 28, 3)\n",
      "Shape of Unlabeled Data: (5806, 28, 28, 3)\n",
      "Accuracy on unlabelled images: 57.2683430933517\n",
      "=============================================\n",
      "0 (5806, 3)\n",
      "Num img per class = 100\n",
      "Number of images getting transferred: 300\n",
      "Accuracy of Pseudo-labelled img added to dataset: 63.0\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 4803      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,195\n",
      "Trainable params: 24,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "6/6 [==============================] - 1s 46ms/step - loss: 1.0909 - accuracy: 0.3812 - val_loss: 1.2494 - val_accuracy: 0.1892\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0662 - accuracy: 0.4539 - val_loss: 1.1010 - val_accuracy: 0.2703\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0264 - accuracy: 0.5401 - val_loss: 1.0918 - val_accuracy: 0.2838\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9826 - accuracy: 0.6036 - val_loss: 1.1282 - val_accuracy: 0.2703\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9056 - accuracy: 0.6626 - val_loss: 0.9515 - val_accuracy: 0.5270\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.8767 - accuracy: 0.6097 - val_loss: 1.0440 - val_accuracy: 0.4730\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.8199 - accuracy: 0.6445 - val_loss: 0.8500 - val_accuracy: 0.6622\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.7938 - accuracy: 0.6717 - val_loss: 0.9990 - val_accuracy: 0.5270\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.7684 - accuracy: 0.6868 - val_loss: 0.7868 - val_accuracy: 0.7027\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.7488 - accuracy: 0.6838 - val_loss: 1.0357 - val_accuracy: 0.5000\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.7411 - accuracy: 0.6974 - val_loss: 0.7959 - val_accuracy: 0.7027\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.7529 - accuracy: 0.6702 - val_loss: 0.9194 - val_accuracy: 0.6081\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.7093 - accuracy: 0.7156 - val_loss: 0.6068 - val_accuracy: 0.7568\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.7069 - accuracy: 0.7050 - val_loss: 0.9164 - val_accuracy: 0.5946\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.7116 - accuracy: 0.7141 - val_loss: 0.7948 - val_accuracy: 0.6892\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.7030 - accuracy: 0.7126 - val_loss: 0.6052 - val_accuracy: 0.7703\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.7052 - accuracy: 0.7156 - val_loss: 0.9909 - val_accuracy: 0.5135\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6868 - accuracy: 0.7322 - val_loss: 0.6135 - val_accuracy: 0.7432\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6781 - accuracy: 0.7292 - val_loss: 0.8386 - val_accuracy: 0.6216\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6832 - accuracy: 0.7080 - val_loss: 0.7365 - val_accuracy: 0.6892\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.6518 - accuracy: 0.7201 - val_loss: 0.7228 - val_accuracy: 0.6622\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.7006 - accuracy: 0.7156 - val_loss: 0.8747 - val_accuracy: 0.5811\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.6713 - accuracy: 0.7201 - val_loss: 0.6570 - val_accuracy: 0.7297\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6656 - accuracy: 0.7383 - val_loss: 0.9842 - val_accuracy: 0.5270\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.6717 - accuracy: 0.7156 - val_loss: 0.5767 - val_accuracy: 0.7027\n",
      "CNN Test accuracy on Lake Set for iteration0:  43.18181872367859\n"
     ]
    }
   ],
   "source": [
    "#  img_per_class: num images added per loop per class\n",
    "x,y,xu,yu,confidence_list = cage_loop(LFS, max_iters=1, threshold=10**-5,  img_per_class = 100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:28:20.373841Z",
     "end_time": "2023-04-26T07:36:59.943455Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feeding CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 4803      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,195\n",
      "Trainable params: 24,195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "6/6 [==============================] - 1s 44ms/step - loss: 1.0909 - accuracy: 0.3812 - val_loss: 1.2494 - val_accuracy: 0.1892\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0662 - accuracy: 0.4539 - val_loss: 1.1010 - val_accuracy: 0.2703\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 1.0264 - accuracy: 0.5401 - val_loss: 1.0918 - val_accuracy: 0.2838\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9826 - accuracy: 0.6036 - val_loss: 1.1282 - val_accuracy: 0.2703\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9056 - accuracy: 0.6626 - val_loss: 0.9515 - val_accuracy: 0.5270\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.8767 - accuracy: 0.6097 - val_loss: 1.0440 - val_accuracy: 0.4730\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.8199 - accuracy: 0.6445 - val_loss: 0.8500 - val_accuracy: 0.6622\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.7938 - accuracy: 0.6717 - val_loss: 0.9990 - val_accuracy: 0.5270\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.7684 - accuracy: 0.6868 - val_loss: 0.7868 - val_accuracy: 0.7027\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.7488 - accuracy: 0.6838 - val_loss: 1.0357 - val_accuracy: 0.5000\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.7411 - accuracy: 0.6974 - val_loss: 0.7959 - val_accuracy: 0.7027\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.7529 - accuracy: 0.6702 - val_loss: 0.9194 - val_accuracy: 0.6081\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.7093 - accuracy: 0.7156 - val_loss: 0.6068 - val_accuracy: 0.7568\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.7069 - accuracy: 0.7050 - val_loss: 0.9164 - val_accuracy: 0.5946\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.7116 - accuracy: 0.7141 - val_loss: 0.7948 - val_accuracy: 0.6892\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.7030 - accuracy: 0.7126 - val_loss: 0.6052 - val_accuracy: 0.7703\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.7052 - accuracy: 0.7156 - val_loss: 0.9909 - val_accuracy: 0.5135\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.6868 - accuracy: 0.7322 - val_loss: 0.6135 - val_accuracy: 0.7432\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6781 - accuracy: 0.7292 - val_loss: 0.8386 - val_accuracy: 0.6216\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.6832 - accuracy: 0.7080 - val_loss: 0.7365 - val_accuracy: 0.6892\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.6518 - accuracy: 0.7201 - val_loss: 0.7228 - val_accuracy: 0.6622\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.7006 - accuracy: 0.7156 - val_loss: 0.8747 - val_accuracy: 0.5811\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.6713 - accuracy: 0.7201 - val_loss: 0.6570 - val_accuracy: 0.7297\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6656 - accuracy: 0.7383 - val_loss: 0.9842 - val_accuracy: 0.5270\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.6717 - accuracy: 0.7156 - val_loss: 0.5767 - val_accuracy: 0.7027\n"
     ]
    }
   ],
   "source": [
    "from cnn import create_cnn\n",
    "from keras.utils import np_utils\n",
    "\n",
    "classes,label_frac,data_path,save_path = get_variables()\n",
    "\n",
    "x_train = x\n",
    "x_train = np.array(x_train).reshape(-1, 28, 28, 3)\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "y_train = [int(i) for i in y]\n",
    "y_train = np_utils.to_categorical(y_train, len(classes))\n",
    "batch_size = 128\n",
    "epochs = 25\n",
    "model = create_cnn(num_classes = 3)\n",
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "model.save('D://project//code//cnn//cage_trained.h5')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:36:59.906945Z",
     "end_time": "2023-04-26T07:37:05.413997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Test accuracy on Test Set:  39.05325531959534\n",
      "CNN Test accuracy on Lake Set:  56.95604681968689\n"
     ]
    }
   ],
   "source": [
    "data,x,y = custom_dataset(classes=[0,1,7],path=data_path ,fraction=0)\n",
    "\n",
    "#For testing on test set\n",
    "X_test = data[\"test_images\"]\n",
    "X_test = np.array(X_test).reshape(-1, 28, 28, 3)\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "y_test = [int(i) for i in data[\"test_labels\"]]\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=3)\n",
    "\n",
    "#For testing on Lake Set\n",
    "Xu_test = xu\n",
    "Xu_test = np.array(Xu_test).reshape(-1, 28, 28, 3)\n",
    "Xu_test = Xu_test.astype(\"float32\") / 255\n",
    "yu_test = [int(i) for i in yu]\n",
    "yu_test = np_utils.to_categorical(yu_test, num_classes=3)\n",
    "\n",
    "test_score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "lake_score = model.evaluate(Xu_test, yu_test, verbose = 0)\n",
    "print(\"CNN Test accuracy on Test Set: \", test_score[1]*100)\n",
    "print(\"CNN Test accuracy on Lake Set: \", lake_score[1]*100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:37:05.415997Z",
     "end_time": "2023-04-26T07:37:07.116041Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a histogram of the data\n",
    "plt.hist(confidence_list[0], bins=10)\n",
    "\n",
    "# Set plot title and axis labels\n",
    "plt.title('Distribution of Confidences output by CAGE')\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:37:07.123042Z",
     "end_time": "2023-04-26T07:37:07.209385Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:37:07.210340Z",
     "end_time": "2023-04-26T07:37:07.254407Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T07:37:07.225751Z",
     "end_time": "2023-04-26T07:37:07.254407Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
